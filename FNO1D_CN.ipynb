{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 基于Fourier Neural Operator的Burgers' equation求解\n",
    "\n",
    "[![下载Notebook](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_notebook.png)](https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/master/mindflow/zh_cn/data_driven/mindspore_burgers_FNO1D.ipynb)&emsp;[![下载样例代码](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_download_code.png)](https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/master/mindflow/zh_cn/data_driven/mindspore_burgers_FNO1D.py)&emsp;[![查看源文件](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source.png)](https://gitee.com/mindspore/docs/blob/master/docs/mindflow/docs/source_zh_cn/data_driven/burgers_FNO1D.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 概述\n",
    "\n",
    "计算流体力学是 21 世纪流体力学领域的重要技术之一，其通过使用数值方法在计算机中对流体力学的控制方程进行求解，从而实现流动的分析、预测和控制。传统的有限元法（finite element method，FEM）和有限差分法（finite difference method，FDM）常用于复杂的仿真流程（物理建模、网格划分、数值离散、迭代求解等）和较高的计算成本，往往效率低下。因此，借助AI提升流体仿真效率是十分必要的。\n",
    "\n",
    "近年来，随着神经网络的迅猛发展，为科学计算提供了新的范式。经典的神经网络是在有限维度的空间进行映射，只能学习与特定离散化相关的解。与经典神经网络不同，傅里叶神经算子（Fourier Neural Operator，FNO）是一种能够学习无限维函数空间映射的新型深度学习架构。该架构可直接学习从任意函数参数到解的映射，用于解决一类偏微分方程的求解问题，具有更强的泛化能力。更多信息可参考[Fourier Neural Operator for Parametric Partial Differential Equations](https://arxiv.org/abs/2010.08895)。\n",
    "\n",
    "本案例教程介绍利用傅里叶神经算子的 1-d Burgers 方程求解方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 伯格斯方程（Burgers' equation）\n",
    "\n",
    "一维伯格斯方程（1-d Burgers' equation）是一个非线性偏微分方程，具有广泛应用，包括一维粘性流体流动建模。它的形式如下：\n",
    "\n",
    "$$\n",
    "\\partial_t u(x, t)+\\partial_x (u^2(x, t)/2)=\\nu \\partial_{xx} u(x, t), \\quad x \\in(0,1), t \\in(0, 1]\n",
    "$$\n",
    "\n",
    "$$\n",
    "u(x, 0)=u_0(x), \\quad x \\in(0,1)\n",
    "$$\n",
    "\n",
    "其中 $u$ 表示速度场, $u_0$ 表示初始条件, $\\nu$ 表示粘度系数。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 问题描述\n",
    "\n",
    "我们利用 Fourier Neural Operator 学习初始状态到下一时刻状态的映射，实现一维 Burgers'方程的求解：\n",
    "\n",
    "$$\n",
    "u_0 \\mapsto u(\\cdot, 1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 技术路径\n",
    "\n",
    "MindFlow 求解该问题的具体流程如下：\n",
    "\n",
    "1. 创建数据集。\n",
    "2. 构建模型。\n",
    "3. 优化器与损失函数。\n",
    "4. 模型训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier Neural Operator\n",
    "\n",
    "Fourier Neural Operator 模型构架如下图所示。图中 $w_0(x)$ 表示初始涡度，通过 Lifting Layer 实现输入向量的高维映射，然后将映射结果作为 Fourier Layer 的输入，进行频域信息的非线性变换，最后由 Decoding Layer 将变换结果映射至最终的预测结果 $w_1(x)$。\n",
    "\n",
    "Lifting Layer、Fourier Layer 以及 Decoding Layer 共同组成了 Fourier Neural Operator。\n",
    "\n",
    "![Fourier Neural Operator模型构架](images/FNO.png)\n",
    "\n",
    "Fourier Layer 网络结构如下图所示。图中 V 表示输入向量，上框表示向量经过傅里叶变换后，经过线性变换 R，过滤高频信息，然后进行傅里叶逆变换；另一分支经过线性变换 W，最后通过激活函数，得到 Fourier Layer 输出向量。\n",
    "\n",
    "![Fourier Layer网络结构](images/FNO-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from mindspore.amp import DynamicLossScaler, auto_mixed_precision, all_finite\n",
    "from mindspore import context, nn, Tensor, set_seed, ops, data_sink, jit, save_checkpoint\n",
    "from mindspore import dtype as mstype\n",
    "from mindflow import FNO1D, RelativeRMSELoss, load_yaml_config, get_warmup_cosine_annealing_lr\n",
    "from mindflow.pde import UnsteadyFlowWithLoss\n",
    "\n",
    "from src import create_training_dataset\n",
    "\n",
    "set_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"GPU\", device_id=0)\n",
    "use_ascend = context.get_context(attr_key='device_target') == \"Ascend\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从 `config` 中获得模型、数据、优化器的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = load_yaml_config('./configs/fno1d.yaml')\n",
    "data_params = config[\"data\"]\n",
    "model_params = config[\"model\"]\n",
    "optimizer_params = config[\"optimizer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 创建数据集\n",
    "\n",
    "下载训练与测试数据集: [data_driven/burgers/fno1d/dataset](https://download.mindspore.cn/mindscience/mindflow/dataset/applications/data_driven/burgers/dataset/)。\n",
    "\n",
    "我们根据 Zongyi Li 在 [Fourier Neural Operator for Parametric Partial Differential Equations](https://arxiv.org/pdf/2010.08895.pdf) 一文中对数据集的设置生成训练数据集与测试数据集。具体设置如下：\n",
    "基于周期性边界，生成满足如下分布的初始条件 $u_0(x)$：\n",
    "\n",
    "$$\n",
    "u_0 \\sim \\mu, \\mu=\\mathcal{N}\\left(0,625(-\\Delta+25 I)^{-2}\\right)\n",
    "$$\n",
    "\n",
    "本案例选取粘度系数 $\\nu=0.1$，并使用分步法求解方程，其中热方程部分在傅里叶空间中精确求解，然后使用前向欧拉方法求解非线性部分。训练集样本量为 1000 个，测试集样本量为 200 个。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation finished\n",
      "input_path:  (1000, 1024, 1)\n",
      "label_path:  (1000, 1024)\n"
     ]
    }
   ],
   "source": [
    "# create training dataset\n",
    "train_dataset = create_training_dataset(data_params, model_params, shuffle=True)\n",
    "\n",
    "# create test dataset\n",
    "test_input, test_label = np.load(os.path.join(data_params[\"root_dir\"], \"test/inputs.npy\")), \\\n",
    "                         np.load(os.path.join(data_params[\"root_dir\"], \"test/label.npy\"))\n",
    "test_input = Tensor(np.expand_dims(test_input, -2), mstype.float32)\n",
    "test_label = Tensor(np.expand_dims(test_label, -2), mstype.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 构建模型\n",
    "\n",
    "网络由1层Lifting layer、1层Decoding layer以及多层Fourier Layer叠加组成：\n",
    "\n",
    "- Lifting layer对应样例代码中`FNO1D.fc0`，将输出数据$x$映射至高维；\n",
    "\n",
    "- 多层Fourier Layer的叠加对应样例代码中`FNO1D.fno_seq`，本案例采用离散傅里叶变换实现时域与频域的转换；\n",
    "\n",
    "- Decoding layer对应代码中`FNO1D.fc1`与`FNO1D.fc2`，获得最终的预测值。\n",
    "\n",
    "基于上述网络结构，进行模型初始化，其中模型参数可在[配置文件](https://gitee.com/mindspore/mindscience/blob/master/MindFlow/applications/data_driven/burgers/fno1d/configs/fno1d.yaml)中修改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:FNO1D_in_channels:1_out_channels:1_modes:16_resolutions:1024_hidden_channels:64_depths:4\n"
     ]
    }
   ],
   "source": [
    "model = FNO1D(\n",
    "            in_channels=model_params[\"in_channels\"],\n",
    "            out_channels=model_params[\"out_channels\"],\n",
    "            n_modes=model_params[\"modes\"],\n",
    "            resolutions=model_params[\"resolutions\"],\n",
    "            hidden_channels=model_params[\"hidden_channels\"],\n",
    "            n_layers=model_params[\"depths\"],\n",
    "            projection_channels=4*model_params[\"hidden_channels\"],\n",
    "        )\n",
    "model_params_list = []\n",
    "for k, v in model_params.items():\n",
    "    model_params_list.append(f\"{k}:{v}\")\n",
    "model_name = \"_\".join(model_params_list)\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "steps_per_epoch = train_dataset.get_dataset_size()\n",
    "lr = get_warmup_cosine_annealing_lr(lr_init=optimizer_params[\"learning_rate\"],\n",
    "                                    last_epoch=optimizer_params[\"epochs\"],\n",
    "                                    steps_per_epoch=steps_per_epoch,\n",
    "                                    warmup_epochs=1)\n",
    "\n",
    "# print(model.trainable_params())\n",
    "# The graph mode requires the name of the parameter to be unique. See https://www.mindspore.cn/docs/zh-CN/r2.2/faq/network_compilation.html for details. There is a situation where training parameters have duplicate names. The following code is used to modify the name of the parameter to make it unique.\n",
    "for param in model.get_parameters():\n",
    "    if param.name == \"0.weight\" and param.shape == (256, 64):\n",
    "        param.name = \"1.weight\"\n",
    "# print(model.trainable_params())\n",
    "\n",
    "optimizer = nn.Adam(model.trainable_params(), learning_rate=Tensor(lr))\n",
    "\n",
    "if use_ascend:\n",
    "    from mindspore.amp import DynamicLossScaler, auto_mixed_precision, all_finite\n",
    "    loss_scaler = DynamicLossScaler(1024, 2, 100)\n",
    "    auto_mixed_precision(model, 'O1')\n",
    "else:\n",
    "    loss_scaler = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 优化器与损失函数\n",
    "\n",
    "使用相对均方根误差作为网络训练损失函数："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 模型训练\n",
    "\n",
    "使用 **MindSpore version >= 2.0.0**, 我们可以使用函数式编程来训练神经网络。 `MindFlow` 为非稳态问题 `UnsteadyFlowWithLoss` 提供了一个训练接口，用于模型训练和评估."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./summary/name:FNO1D_in_channels:1_out_channels:1_modes:16_resolutions:1024_hidden_channels:64_depths:4\n",
      "./summary/name:FNO1D_in_channels:1_out_channels:1_modes:16_resolutions:1024_hidden_channels:64_depths:4/ckpt\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] CORE(11177,7fceb07946c0,python):2024-06-11-21:44:03.619.457 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_11177/4031523562.py]\n",
      "[ERROR] CORE(11177,7fceb07946c0,python):2024-06-11-21:44:03.619.508 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_11177/4031523562.py]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 train loss: 0.85617751 epoch time: 4.60s step time: 0.0368s\n",
      "epoch: 2 train loss: 0.61584151 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 3 train loss: 0.88348949 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 4 train loss: 0.52564389 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 5 train loss: 0.69424516 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 6 train loss: 0.52988422 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 7 train loss: 0.41870886 epoch time: 1.28s step time: 0.0103s\n",
      "epoch: 8 train loss: 0.35692692 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 9 train loss: 0.35873815 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 10 train loss: 0.37410733 epoch time: 1.29s step time: 0.0103s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.051916137\n",
      "=================================End Evaluation=================================\n",
      "epoch: 11 train loss: 0.37660101 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 12 train loss: 0.34695560 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 13 train loss: 0.30883470 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 14 train loss: 0.34838066 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 15 train loss: 0.25783288 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 16 train loss: 0.22045958 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 17 train loss: 0.33814690 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 18 train loss: 0.33689943 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 19 train loss: 0.21502268 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 20 train loss: 0.19231296 epoch time: 1.33s step time: 0.0107s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.027574413\n",
      "=================================End Evaluation=================================\n",
      "epoch: 21 train loss: 0.26415092 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 22 train loss: 0.33089918 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 23 train loss: 0.26182526 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 24 train loss: 0.38377082 epoch time: 1.28s step time: 0.0102s\n",
      "epoch: 25 train loss: 0.32899612 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 26 train loss: 0.39063060 epoch time: 1.28s step time: 0.0103s\n",
      "epoch: 27 train loss: 0.16417408 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 28 train loss: 0.31438375 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 29 train loss: 0.19848397 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 30 train loss: 0.24966189 epoch time: 1.33s step time: 0.0106s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.031081762\n",
      "=================================End Evaluation=================================\n",
      "epoch: 31 train loss: 0.21200383 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 32 train loss: 0.15215722 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 33 train loss: 0.17753354 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 34 train loss: 0.21946514 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 35 train loss: 0.21316950 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 36 train loss: 0.16304275 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 37 train loss: 0.42983741 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 38 train loss: 0.23644984 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 39 train loss: 0.28386873 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 40 train loss: 0.31065780 epoch time: 1.31s step time: 0.0104s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.030316649\n",
      "=================================End Evaluation=================================\n",
      "epoch: 41 train loss: 0.17581929 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 42 train loss: 0.18537501 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 43 train loss: 0.19099432 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 44 train loss: 0.38995594 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 45 train loss: 0.13049337 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 46 train loss: 0.11385308 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 47 train loss: 0.20450392 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 48 train loss: 0.19917628 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 49 train loss: 0.19986102 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 50 train loss: 0.20369156 epoch time: 1.30s step time: 0.0104s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.020266721\n",
      "=================================End Evaluation=================================\n",
      "epoch: 51 train loss: 0.14304455 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 52 train loss: 0.16506791 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 53 train loss: 0.24518159 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 54 train loss: 0.15527314 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 55 train loss: 0.22791117 epoch time: 1.29s step time: 0.0104s\n",
      "epoch: 56 train loss: 0.21079561 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 57 train loss: 0.24546456 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 58 train loss: 0.18968613 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 59 train loss: 0.16847378 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 60 train loss: 0.13757925 epoch time: 1.32s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.02134926\n",
      "=================================End Evaluation=================================\n",
      "epoch: 61 train loss: 0.13731843 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 62 train loss: 0.15259653 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 63 train loss: 0.23619083 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 64 train loss: 0.17002976 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 65 train loss: 0.17075735 epoch time: 1.35s step time: 0.0108s\n",
      "epoch: 66 train loss: 0.13774535 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 67 train loss: 0.16418165 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 68 train loss: 0.15454823 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 69 train loss: 0.26779956 epoch time: 1.28s step time: 0.0103s\n",
      "epoch: 70 train loss: 0.15101771 epoch time: 1.31s step time: 0.0104s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.025206542\n",
      "=================================End Evaluation=================================\n",
      "epoch: 71 train loss: 0.09785438 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 72 train loss: 0.16398516 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 73 train loss: 0.14702839 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 74 train loss: 0.20692721 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 75 train loss: 0.30695432 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 76 train loss: 0.29537463 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 77 train loss: 0.26354542 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 78 train loss: 0.28657237 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 79 train loss: 0.13767880 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 80 train loss: 0.14035591 epoch time: 1.36s step time: 0.0109s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.027653687\n",
      "=================================End Evaluation=================================\n",
      "epoch: 81 train loss: 0.13368589 epoch time: 1.29s step time: 0.0104s\n",
      "epoch: 82 train loss: 0.12452944 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 83 train loss: 0.11299807 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 84 train loss: 0.10419922 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 85 train loss: 0.21860236 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 86 train loss: 0.21411742 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 87 train loss: 0.18622857 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 88 train loss: 0.15118930 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 89 train loss: 0.15207332 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 90 train loss: 0.16561669 epoch time: 1.30s step time: 0.0104s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.021124467\n",
      "=================================End Evaluation=================================\n",
      "epoch: 91 train loss: 0.10155664 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 92 train loss: 0.18463463 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 93 train loss: 0.12049615 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 94 train loss: 0.11465491 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 95 train loss: 0.10542176 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 96 train loss: 0.17957124 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 97 train loss: 0.19192708 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 98 train loss: 0.11606629 epoch time: 1.35s step time: 0.0108s\n",
      "epoch: 99 train loss: 0.17372347 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 100 train loss: 0.14351037 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0137593495\n",
      "=================================End Evaluation=================================\n",
      "epoch: 101 train loss: 0.09785755 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 102 train loss: 0.13627318 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 103 train loss: 0.19346783 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 104 train loss: 0.11774552 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 105 train loss: 0.14863911 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 106 train loss: 0.15511706 epoch time: 1.33s step time: 0.0107s\n",
      "epoch: 107 train loss: 0.16838092 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 108 train loss: 0.12198817 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 109 train loss: 0.14683294 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 110 train loss: 0.08998659 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.012783346\n",
      "=================================End Evaluation=================================\n",
      "epoch: 111 train loss: 0.19202152 epoch time: 1.38s step time: 0.0111s\n",
      "epoch: 112 train loss: 0.08762299 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 113 train loss: 0.20579168 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 114 train loss: 0.11050785 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 115 train loss: 0.15045953 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 116 train loss: 0.19127455 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 117 train loss: 0.13565931 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 118 train loss: 0.08865301 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 119 train loss: 0.15339437 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 120 train loss: 0.10831418 epoch time: 1.32s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.017336745\n",
      "=================================End Evaluation=================================\n",
      "epoch: 121 train loss: 0.10224460 epoch time: 1.35s step time: 0.0108s\n",
      "epoch: 122 train loss: 0.13297723 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 123 train loss: 0.25594547 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 124 train loss: 0.15674949 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 125 train loss: 0.10790937 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 126 train loss: 0.11090347 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 127 train loss: 0.11284135 epoch time: 1.35s step time: 0.0108s\n",
      "epoch: 128 train loss: 0.15371107 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 129 train loss: 0.09460908 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 130 train loss: 0.12250313 epoch time: 1.30s step time: 0.0104s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.016723603\n",
      "=================================End Evaluation=================================\n",
      "epoch: 131 train loss: 0.10620551 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 132 train loss: 0.12683377 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 133 train loss: 0.13690361 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 134 train loss: 0.23879153 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 135 train loss: 0.11426110 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 136 train loss: 0.14466719 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 137 train loss: 0.16721460 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 138 train loss: 0.10278861 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 139 train loss: 0.10824371 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 140 train loss: 0.07774698 epoch time: 1.30s step time: 0.0104s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.014398127\n",
      "=================================End Evaluation=================================\n",
      "epoch: 141 train loss: 0.10750046 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 142 train loss: 0.22255236 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 143 train loss: 0.12632598 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 144 train loss: 0.14112389 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 145 train loss: 0.13275951 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 146 train loss: 0.13909762 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 147 train loss: 0.14622271 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 148 train loss: 0.13288677 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 149 train loss: 0.10388014 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 150 train loss: 0.10059362 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.014492054\n",
      "=================================End Evaluation=================================\n",
      "epoch: 151 train loss: 0.15688288 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 152 train loss: 0.14668401 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 153 train loss: 0.12789065 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 154 train loss: 0.10291798 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 155 train loss: 0.15238887 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 156 train loss: 0.08940428 epoch time: 1.38s step time: 0.0110s\n",
      "epoch: 157 train loss: 0.14007995 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 158 train loss: 0.09535672 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 159 train loss: 0.18437660 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 160 train loss: 0.11366273 epoch time: 1.31s step time: 0.0104s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.017792322\n",
      "=================================End Evaluation=================================\n",
      "epoch: 161 train loss: 0.12195065 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 162 train loss: 0.19582823 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 163 train loss: 0.14138164 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 164 train loss: 0.15279296 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 165 train loss: 0.11593732 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 166 train loss: 0.20518202 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 167 train loss: 0.09205838 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 168 train loss: 0.11836196 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 169 train loss: 0.09396119 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 170 train loss: 0.22749126 epoch time: 1.32s step time: 0.0106s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.022467025\n",
      "=================================End Evaluation=================================\n",
      "epoch: 171 train loss: 0.16382363 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 172 train loss: 0.08258715 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 173 train loss: 0.10998537 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 174 train loss: 0.09848899 epoch time: 1.33s step time: 0.0107s\n",
      "epoch: 175 train loss: 0.17467061 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 176 train loss: 0.10403840 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 177 train loss: 0.09975079 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 178 train loss: 0.10934374 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 179 train loss: 0.07146218 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 180 train loss: 0.13587761 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.021347592\n",
      "=================================End Evaluation=================================\n",
      "epoch: 181 train loss: 0.06007821 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 182 train loss: 0.12654766 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 183 train loss: 0.10570434 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 184 train loss: 0.10376592 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 185 train loss: 0.09571342 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 186 train loss: 0.11383204 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 187 train loss: 0.12074057 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 188 train loss: 0.06578233 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 189 train loss: 0.09198399 epoch time: 1.33s step time: 0.0107s\n",
      "epoch: 190 train loss: 0.07173464 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.02149462\n",
      "=================================End Evaluation=================================\n",
      "epoch: 191 train loss: 0.08192467 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 192 train loss: 0.11372950 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 193 train loss: 0.14524049 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 194 train loss: 0.10752101 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 195 train loss: 0.10827569 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 196 train loss: 0.14833915 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 197 train loss: 0.10436927 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 198 train loss: 0.11822343 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 199 train loss: 0.16093598 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 200 train loss: 0.09721073 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.011506762\n",
      "=================================End Evaluation=================================\n",
      "epoch: 201 train loss: 0.08130072 epoch time: 1.37s step time: 0.0109s\n",
      "epoch: 202 train loss: 0.09055406 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 203 train loss: 0.06919800 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 204 train loss: 0.07993606 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 205 train loss: 0.10705785 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 206 train loss: 0.09709071 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 207 train loss: 0.15909967 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 208 train loss: 0.11354157 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 209 train loss: 0.08454400 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 210 train loss: 0.07279631 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.01106777\n",
      "=================================End Evaluation=================================\n",
      "epoch: 211 train loss: 0.08422675 epoch time: 1.36s step time: 0.0109s\n",
      "epoch: 212 train loss: 0.11291298 epoch time: 1.33s step time: 0.0107s\n",
      "epoch: 213 train loss: 0.05541346 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 214 train loss: 0.07535201 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 215 train loss: 0.08681904 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 216 train loss: 0.07180112 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 217 train loss: 0.09628599 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 218 train loss: 0.12558615 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 219 train loss: 0.08942679 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 220 train loss: 0.09810527 epoch time: 1.32s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.012497449\n",
      "=================================End Evaluation=================================\n",
      "epoch: 221 train loss: 0.09084582 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 222 train loss: 0.08946839 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 223 train loss: 0.10613774 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 224 train loss: 0.08072136 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 225 train loss: 0.07432100 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 226 train loss: 0.08008983 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 227 train loss: 0.06755032 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 228 train loss: 0.07838480 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 229 train loss: 0.08905986 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 230 train loss: 0.13258153 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0162495\n",
      "=================================End Evaluation=================================\n",
      "epoch: 231 train loss: 0.08690178 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 232 train loss: 0.11794185 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 233 train loss: 0.08999396 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 234 train loss: 0.11936744 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 235 train loss: 0.08978917 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 236 train loss: 0.07378010 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 237 train loss: 0.08192599 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 238 train loss: 0.08057994 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 239 train loss: 0.09661949 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 240 train loss: 0.11091255 epoch time: 1.31s step time: 0.0104s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.014755555\n",
      "=================================End Evaluation=================================\n",
      "epoch: 241 train loss: 0.08902758 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 242 train loss: 0.14036307 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 243 train loss: 0.08327500 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 244 train loss: 0.10378549 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 245 train loss: 0.07740448 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 246 train loss: 0.06647721 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 247 train loss: 0.08630656 epoch time: 1.36s step time: 0.0109s\n",
      "epoch: 248 train loss: 0.11738196 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 249 train loss: 0.09969329 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 250 train loss: 0.10496016 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.014146562\n",
      "=================================End Evaluation=================================\n",
      "epoch: 251 train loss: 0.12970059 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 252 train loss: 0.08785824 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 253 train loss: 0.21421947 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 254 train loss: 0.07756321 epoch time: 1.33s step time: 0.0107s\n",
      "epoch: 255 train loss: 0.09662785 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 256 train loss: 0.14987499 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 257 train loss: 0.07755982 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 258 train loss: 0.08984347 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 259 train loss: 0.10566819 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 260 train loss: 0.07559432 epoch time: 1.33s step time: 0.0106s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.009572673\n",
      "=================================End Evaluation=================================\n",
      "epoch: 261 train loss: 0.08870625 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 262 train loss: 0.05952536 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 263 train loss: 0.07402882 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 264 train loss: 0.08835900 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 265 train loss: 0.11185724 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 266 train loss: 0.09141673 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 267 train loss: 0.12529618 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 268 train loss: 0.05836445 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 269 train loss: 0.06073105 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 270 train loss: 0.09725381 epoch time: 1.36s step time: 0.0108s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.010284238\n",
      "=================================End Evaluation=================================\n",
      "epoch: 271 train loss: 0.05762212 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 272 train loss: 0.05025554 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 273 train loss: 0.09509936 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 274 train loss: 0.06659628 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 275 train loss: 0.15059160 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 276 train loss: 0.11102444 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 277 train loss: 0.14977059 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 278 train loss: 0.09867133 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 279 train loss: 0.08512466 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 280 train loss: 0.09414865 epoch time: 1.32s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.012551839\n",
      "=================================End Evaluation=================================\n",
      "epoch: 281 train loss: 0.04905182 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 282 train loss: 0.06883176 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 283 train loss: 0.08831741 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 284 train loss: 0.11141212 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 285 train loss: 0.09273309 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 286 train loss: 0.06557254 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 287 train loss: 0.13039663 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 288 train loss: 0.09309827 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 289 train loss: 0.07451994 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 290 train loss: 0.10282546 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.011106895\n",
      "=================================End Evaluation=================================\n",
      "epoch: 291 train loss: 0.11177770 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 292 train loss: 0.08192971 epoch time: 1.40s step time: 0.0112s\n",
      "epoch: 293 train loss: 0.05032299 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 294 train loss: 0.12692422 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 295 train loss: 0.07209484 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 296 train loss: 0.08389874 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 297 train loss: 0.10984050 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 298 train loss: 0.06087031 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 299 train loss: 0.04170856 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 300 train loss: 0.11987975 epoch time: 1.32s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.013764069\n",
      "=================================End Evaluation=================================\n",
      "epoch: 301 train loss: 0.06520773 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 302 train loss: 0.10738983 epoch time: 1.33s step time: 0.0107s\n",
      "epoch: 303 train loss: 0.08957691 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 304 train loss: 0.08506494 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 305 train loss: 0.08960769 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 306 train loss: 0.11214409 epoch time: 1.36s step time: 0.0109s\n",
      "epoch: 307 train loss: 0.08703712 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 308 train loss: 0.09440848 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 309 train loss: 0.12761156 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 310 train loss: 0.07360833 epoch time: 1.32s step time: 0.0106s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.011890621\n",
      "=================================End Evaluation=================================\n",
      "epoch: 311 train loss: 0.08589381 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 312 train loss: 0.14276201 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 313 train loss: 0.12751855 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 314 train loss: 0.06001756 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 315 train loss: 0.05572452 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 316 train loss: 0.05777869 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 317 train loss: 0.07944942 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 318 train loss: 0.10135695 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 319 train loss: 0.07717141 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 320 train loss: 0.09189336 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.009520436\n",
      "=================================End Evaluation=================================\n",
      "epoch: 321 train loss: 0.10322389 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 322 train loss: 0.06345820 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 323 train loss: 0.08319075 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 324 train loss: 0.09422670 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 325 train loss: 0.05671329 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 326 train loss: 0.05805060 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 327 train loss: 0.08313943 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 328 train loss: 0.11240730 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 329 train loss: 0.08852805 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 330 train loss: 0.04634642 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.012109741\n",
      "=================================End Evaluation=================================\n",
      "epoch: 331 train loss: 0.13002244 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 332 train loss: 0.13776852 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 333 train loss: 0.08631091 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 334 train loss: 0.07327093 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 335 train loss: 0.11363582 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 336 train loss: 0.05006003 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 337 train loss: 0.15378943 epoch time: 1.43s step time: 0.0114s\n",
      "epoch: 338 train loss: 0.04780323 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 339 train loss: 0.04771998 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 340 train loss: 0.06718552 epoch time: 1.35s step time: 0.0108s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.00754043\n",
      "=================================End Evaluation=================================\n",
      "epoch: 341 train loss: 0.05239614 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 342 train loss: 0.10935944 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 343 train loss: 0.04927475 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 344 train loss: 0.08621475 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 345 train loss: 0.09720920 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 346 train loss: 0.06188846 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 347 train loss: 0.06196700 epoch time: 1.36s step time: 0.0109s\n",
      "epoch: 348 train loss: 0.06746717 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 349 train loss: 0.04837697 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 350 train loss: 0.07984594 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.009339702\n",
      "=================================End Evaluation=================================\n",
      "epoch: 351 train loss: 0.08572423 epoch time: 1.35s step time: 0.0108s\n",
      "epoch: 352 train loss: 0.08671939 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 353 train loss: 0.09527261 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 354 train loss: 0.10757071 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 355 train loss: 0.09142514 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 356 train loss: 0.05224968 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 357 train loss: 0.12415798 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 358 train loss: 0.04439974 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 359 train loss: 0.05745221 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 360 train loss: 0.07227738 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.009547897\n",
      "=================================End Evaluation=================================\n",
      "epoch: 361 train loss: 0.05615603 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 362 train loss: 0.07591987 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 363 train loss: 0.04553908 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 364 train loss: 0.05101464 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 365 train loss: 0.06012110 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 366 train loss: 0.06032458 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 367 train loss: 0.10793598 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 368 train loss: 0.06810862 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 369 train loss: 0.11972565 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 370 train loss: 0.05758305 epoch time: 1.34s step time: 0.0107s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0072557093\n",
      "=================================End Evaluation=================================\n",
      "epoch: 371 train loss: 0.06064500 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 372 train loss: 0.08415270 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 373 train loss: 0.04968965 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 374 train loss: 0.05099075 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 375 train loss: 0.06437485 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 376 train loss: 0.05715745 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 377 train loss: 0.07761343 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 378 train loss: 0.08043092 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 379 train loss: 0.07442339 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 380 train loss: 0.10055539 epoch time: 1.32s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.012439569\n",
      "=================================End Evaluation=================================\n",
      "epoch: 381 train loss: 0.06959264 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 382 train loss: 0.05122585 epoch time: 1.38s step time: 0.0110s\n",
      "epoch: 383 train loss: 0.06803910 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 384 train loss: 0.09145100 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 385 train loss: 0.04012455 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 386 train loss: 0.06836280 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 387 train loss: 0.09741187 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 388 train loss: 0.03551614 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 389 train loss: 0.05995121 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 390 train loss: 0.08344771 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.012747239\n",
      "=================================End Evaluation=================================\n",
      "epoch: 391 train loss: 0.07730007 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 392 train loss: 0.07325172 epoch time: 1.33s step time: 0.0107s\n",
      "epoch: 393 train loss: 0.07646748 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 394 train loss: 0.06832367 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 395 train loss: 0.05500463 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 396 train loss: 0.06578727 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 397 train loss: 0.05187277 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 398 train loss: 0.06702366 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 399 train loss: 0.04632476 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 400 train loss: 0.07830562 epoch time: 1.35s step time: 0.0108s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.010090126\n",
      "=================================End Evaluation=================================\n",
      "epoch: 401 train loss: 0.08990870 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 402 train loss: 0.05307171 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 403 train loss: 0.04650741 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 404 train loss: 0.04427274 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 405 train loss: 0.05368294 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 406 train loss: 0.09068582 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 407 train loss: 0.05297534 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 408 train loss: 0.09059925 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 409 train loss: 0.05569976 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 410 train loss: 0.06610857 epoch time: 1.32s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.00687745\n",
      "=================================End Evaluation=================================\n",
      "epoch: 411 train loss: 0.05001871 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 412 train loss: 0.08828412 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 413 train loss: 0.07686614 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 414 train loss: 0.08253953 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 415 train loss: 0.08717094 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 416 train loss: 0.11296610 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 417 train loss: 0.06146553 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 418 train loss: 0.04350304 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 419 train loss: 0.04922812 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 420 train loss: 0.04718670 epoch time: 1.30s step time: 0.0104s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.010805092\n",
      "=================================End Evaluation=================================\n",
      "epoch: 421 train loss: 0.07913563 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 422 train loss: 0.05881153 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 423 train loss: 0.07172896 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 424 train loss: 0.03668245 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 425 train loss: 0.04863353 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 426 train loss: 0.06060216 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 427 train loss: 0.06201129 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 428 train loss: 0.04713985 epoch time: 1.33s step time: 0.0107s\n",
      "epoch: 429 train loss: 0.11867432 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 430 train loss: 0.04494552 epoch time: 1.33s step time: 0.0107s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.007910372\n",
      "=================================End Evaluation=================================\n",
      "epoch: 431 train loss: 0.06698161 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 432 train loss: 0.07096981 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 433 train loss: 0.05178459 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 434 train loss: 0.04892480 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 435 train loss: 0.03399111 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 436 train loss: 0.07070635 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 437 train loss: 0.05999833 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 438 train loss: 0.05793994 epoch time: 1.35s step time: 0.0108s\n",
      "epoch: 439 train loss: 0.08182962 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 440 train loss: 0.09596393 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.012470825\n",
      "=================================End Evaluation=================================\n",
      "epoch: 441 train loss: 0.04590923 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 442 train loss: 0.04348243 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 443 train loss: 0.04524061 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 444 train loss: 0.05237645 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 445 train loss: 0.08583730 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 446 train loss: 0.06217829 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 447 train loss: 0.04995886 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 448 train loss: 0.03856576 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 449 train loss: 0.04382486 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 450 train loss: 0.04861251 epoch time: 1.32s step time: 0.0106s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.009859111\n",
      "=================================End Evaluation=================================\n",
      "epoch: 451 train loss: 0.06247167 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 452 train loss: 0.07445450 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 453 train loss: 0.06100241 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 454 train loss: 0.06243918 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 455 train loss: 0.04719471 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 456 train loss: 0.05100540 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 457 train loss: 0.08903344 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 458 train loss: 0.05634943 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 459 train loss: 0.07099226 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 460 train loss: 0.06064110 epoch time: 1.33s step time: 0.0106s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.007898215\n",
      "=================================End Evaluation=================================\n",
      "epoch: 461 train loss: 0.06449651 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 462 train loss: 0.05598454 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 463 train loss: 0.06411798 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 464 train loss: 0.07519902 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 465 train loss: 0.10638369 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 466 train loss: 0.06393128 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 467 train loss: 0.04795574 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 468 train loss: 0.06362629 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 469 train loss: 0.05246641 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 470 train loss: 0.03289100 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.008043989\n",
      "=================================End Evaluation=================================\n",
      "epoch: 471 train loss: 0.04176724 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 472 train loss: 0.06594527 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 473 train loss: 0.03398799 epoch time: 1.35s step time: 0.0108s\n",
      "epoch: 474 train loss: 0.04224707 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 475 train loss: 0.04025716 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 476 train loss: 0.04813584 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 477 train loss: 0.05613871 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 478 train loss: 0.04520884 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 479 train loss: 0.05415009 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 480 train loss: 0.06318773 epoch time: 1.32s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0064371256\n",
      "=================================End Evaluation=================================\n",
      "epoch: 481 train loss: 0.06455067 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 482 train loss: 0.06825373 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 483 train loss: 0.05304420 epoch time: 1.35s step time: 0.0108s\n",
      "epoch: 484 train loss: 0.03944813 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 485 train loss: 0.05772784 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 486 train loss: 0.04226653 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 487 train loss: 0.05731038 epoch time: 1.33s step time: 0.0107s\n",
      "epoch: 488 train loss: 0.06344654 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 489 train loss: 0.06548145 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 490 train loss: 0.05364906 epoch time: 1.34s step time: 0.0107s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.008410957\n",
      "=================================End Evaluation=================================\n",
      "epoch: 491 train loss: 0.03910717 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 492 train loss: 0.04273519 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 493 train loss: 0.04642609 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 494 train loss: 0.05818780 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 495 train loss: 0.06753093 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 496 train loss: 0.04163969 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 497 train loss: 0.03502291 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 498 train loss: 0.05633762 epoch time: 1.35s step time: 0.0108s\n",
      "epoch: 499 train loss: 0.06057617 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 500 train loss: 0.04701861 epoch time: 1.32s step time: 0.0106s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.00687487\n",
      "=================================End Evaluation=================================\n",
      "epoch: 501 train loss: 0.04932388 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 502 train loss: 0.03528541 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 503 train loss: 0.03387379 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 504 train loss: 0.04425731 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 505 train loss: 0.03656601 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 506 train loss: 0.06647634 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 507 train loss: 0.04015644 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 508 train loss: 0.04124380 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 509 train loss: 0.06536213 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 510 train loss: 0.05516748 epoch time: 1.33s step time: 0.0106s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.009524498\n",
      "=================================End Evaluation=================================\n",
      "epoch: 511 train loss: 0.06516912 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 512 train loss: 0.06174826 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 513 train loss: 0.03973441 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 514 train loss: 0.04118084 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 515 train loss: 0.07503662 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 516 train loss: 0.08797946 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 517 train loss: 0.06946445 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 518 train loss: 0.05545590 epoch time: 1.39s step time: 0.0111s\n",
      "epoch: 519 train loss: 0.05807986 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 520 train loss: 0.06648953 epoch time: 1.33s step time: 0.0106s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.00970686\n",
      "=================================End Evaluation=================================\n",
      "epoch: 521 train loss: 0.02544185 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 522 train loss: 0.03973111 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 523 train loss: 0.04279244 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 524 train loss: 0.06350705 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 525 train loss: 0.03724759 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 526 train loss: 0.04727120 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 527 train loss: 0.03168795 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 528 train loss: 0.03039967 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 529 train loss: 0.03732089 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 530 train loss: 0.03666458 epoch time: 1.32s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0071195234\n",
      "=================================End Evaluation=================================\n",
      "epoch: 531 train loss: 0.08635832 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 532 train loss: 0.04123697 epoch time: 1.34s step time: 0.0108s\n",
      "epoch: 533 train loss: 0.03557222 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 534 train loss: 0.02606904 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 535 train loss: 0.04620063 epoch time: 1.33s step time: 0.0107s\n",
      "epoch: 536 train loss: 0.06868003 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 537 train loss: 0.06644709 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 538 train loss: 0.02367176 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 539 train loss: 0.04453293 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 540 train loss: 0.07748578 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.006761611\n",
      "=================================End Evaluation=================================\n",
      "epoch: 541 train loss: 0.04799131 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 542 train loss: 0.04686920 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 543 train loss: 0.06407191 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 544 train loss: 0.06130634 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 545 train loss: 0.05420817 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 546 train loss: 0.02691287 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 547 train loss: 0.03086399 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 548 train loss: 0.06016082 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 549 train loss: 0.04699289 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 550 train loss: 0.06076309 epoch time: 1.32s step time: 0.0106s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.007915072\n",
      "=================================End Evaluation=================================\n",
      "epoch: 551 train loss: 0.02948603 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 552 train loss: 0.04625674 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 553 train loss: 0.03437712 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 554 train loss: 0.03077946 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 555 train loss: 0.03551634 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 556 train loss: 0.03876659 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 557 train loss: 0.05382208 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 558 train loss: 0.03435296 epoch time: 1.35s step time: 0.0108s\n",
      "epoch: 559 train loss: 0.05899705 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 560 train loss: 0.04415194 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0061315172\n",
      "=================================End Evaluation=================================\n",
      "epoch: 561 train loss: 0.07841550 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 562 train loss: 0.04019786 epoch time: 1.33s step time: 0.0107s\n",
      "epoch: 563 train loss: 0.03965020 epoch time: 1.41s step time: 0.0113s\n",
      "epoch: 564 train loss: 0.02931336 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 565 train loss: 0.03233352 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 566 train loss: 0.03642883 epoch time: 1.35s step time: 0.0108s\n",
      "epoch: 567 train loss: 0.03125782 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 568 train loss: 0.04653820 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 569 train loss: 0.04014626 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 570 train loss: 0.03680371 epoch time: 1.32s step time: 0.0106s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0061092316\n",
      "=================================End Evaluation=================================\n",
      "epoch: 571 train loss: 0.03728605 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 572 train loss: 0.03587511 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 573 train loss: 0.04494101 epoch time: 1.35s step time: 0.0108s\n",
      "epoch: 574 train loss: 0.05089308 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 575 train loss: 0.03943130 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 576 train loss: 0.04470798 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 577 train loss: 0.05531586 epoch time: 1.35s step time: 0.0108s\n",
      "epoch: 578 train loss: 0.02913854 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 579 train loss: 0.05377778 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 580 train loss: 0.04222921 epoch time: 1.34s step time: 0.0107s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0058135204\n",
      "=================================End Evaluation=================================\n",
      "epoch: 581 train loss: 0.03005814 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 582 train loss: 0.03848062 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 583 train loss: 0.04241858 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 584 train loss: 0.05688288 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 585 train loss: 0.03059716 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 586 train loss: 0.05318105 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 587 train loss: 0.03150248 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 588 train loss: 0.04696999 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 589 train loss: 0.03550289 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 590 train loss: 0.02143033 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0054185353\n",
      "=================================End Evaluation=================================\n",
      "epoch: 591 train loss: 0.04342191 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 592 train loss: 0.03989938 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 593 train loss: 0.03366354 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 594 train loss: 0.03051491 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 595 train loss: 0.02975861 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 596 train loss: 0.02569590 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 597 train loss: 0.04059989 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 598 train loss: 0.02940171 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 599 train loss: 0.05394576 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 600 train loss: 0.03160127 epoch time: 1.32s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0057732933\n",
      "=================================End Evaluation=================================\n",
      "epoch: 601 train loss: 0.04209635 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 602 train loss: 0.04315664 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 603 train loss: 0.03430108 epoch time: 1.33s step time: 0.0107s\n",
      "epoch: 604 train loss: 0.04469717 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 605 train loss: 0.03784642 epoch time: 1.33s step time: 0.0107s\n",
      "epoch: 606 train loss: 0.03278891 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 607 train loss: 0.02191820 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 608 train loss: 0.04573436 epoch time: 1.38s step time: 0.0111s\n",
      "epoch: 609 train loss: 0.04117494 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 610 train loss: 0.04651247 epoch time: 1.32s step time: 0.0106s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0063903974\n",
      "=================================End Evaluation=================================\n",
      "epoch: 611 train loss: 0.02346797 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 612 train loss: 0.04176844 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 613 train loss: 0.03297143 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 614 train loss: 0.04325823 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 615 train loss: 0.02933082 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 616 train loss: 0.03984836 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 617 train loss: 0.02303291 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 618 train loss: 0.03699614 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 619 train loss: 0.02827838 epoch time: 1.33s step time: 0.0107s\n",
      "epoch: 620 train loss: 0.03101965 epoch time: 1.32s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0052614035\n",
      "=================================End Evaluation=================================\n",
      "epoch: 621 train loss: 0.03212336 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 622 train loss: 0.07065779 epoch time: 1.33s step time: 0.0107s\n",
      "epoch: 623 train loss: 0.03096936 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 624 train loss: 0.03829260 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 625 train loss: 0.05100462 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 626 train loss: 0.03605524 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 627 train loss: 0.02471793 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 628 train loss: 0.03755679 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 629 train loss: 0.02451980 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 630 train loss: 0.02930845 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0056582256\n",
      "=================================End Evaluation=================================\n",
      "epoch: 631 train loss: 0.02344593 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 632 train loss: 0.05064659 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 633 train loss: 0.03674816 epoch time: 1.35s step time: 0.0108s\n",
      "epoch: 634 train loss: 0.04001852 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 635 train loss: 0.02669830 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 636 train loss: 0.02700576 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 637 train loss: 0.02159458 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 638 train loss: 0.03667100 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 639 train loss: 0.02452341 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 640 train loss: 0.03311443 epoch time: 1.31s step time: 0.0104s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.005841689\n",
      "=================================End Evaluation=================================\n",
      "epoch: 641 train loss: 0.04341156 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 642 train loss: 0.04767642 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 643 train loss: 0.04429514 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 644 train loss: 0.03105418 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 645 train loss: 0.03123889 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 646 train loss: 0.02568966 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 647 train loss: 0.04112665 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 648 train loss: 0.03933783 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 649 train loss: 0.03442093 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 650 train loss: 0.02252822 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0048010787\n",
      "=================================End Evaluation=================================\n",
      "epoch: 651 train loss: 0.02468696 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 652 train loss: 0.02167051 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 653 train loss: 0.03630332 epoch time: 1.37s step time: 0.0110s\n",
      "epoch: 654 train loss: 0.03321316 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 655 train loss: 0.03359067 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 656 train loss: 0.04086439 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 657 train loss: 0.03117122 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 658 train loss: 0.03267961 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 659 train loss: 0.03473254 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 660 train loss: 0.03246388 epoch time: 1.30s step time: 0.0104s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0055033057\n",
      "=================================End Evaluation=================================\n",
      "epoch: 661 train loss: 0.02991719 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 662 train loss: 0.03684576 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 663 train loss: 0.04721974 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 664 train loss: 0.02491649 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 665 train loss: 0.02603691 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 666 train loss: 0.04574044 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 667 train loss: 0.02892428 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 668 train loss: 0.03029070 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 669 train loss: 0.02903495 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 670 train loss: 0.03702992 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0063208845\n",
      "=================================End Evaluation=================================\n",
      "epoch: 671 train loss: 0.02162428 epoch time: 1.33s step time: 0.0107s\n",
      "epoch: 672 train loss: 0.02725909 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 673 train loss: 0.01809187 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 674 train loss: 0.03716424 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 675 train loss: 0.03855839 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 676 train loss: 0.02392912 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 677 train loss: 0.03221048 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 678 train loss: 0.03051950 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 679 train loss: 0.01768788 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 680 train loss: 0.03478655 epoch time: 1.29s step time: 0.0104s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0057565565\n",
      "=================================End Evaluation=================================\n",
      "epoch: 681 train loss: 0.03637156 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 682 train loss: 0.02465698 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 683 train loss: 0.03576528 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 684 train loss: 0.02094015 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 685 train loss: 0.02651707 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 686 train loss: 0.02447845 epoch time: 1.35s step time: 0.0108s\n",
      "epoch: 687 train loss: 0.03123602 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 688 train loss: 0.01927121 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 689 train loss: 0.01967418 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 690 train loss: 0.03485875 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0054295408\n",
      "=================================End Evaluation=================================\n",
      "epoch: 691 train loss: 0.02476541 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 692 train loss: 0.02196366 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 693 train loss: 0.03288597 epoch time: 1.35s step time: 0.0108s\n",
      "epoch: 694 train loss: 0.02291600 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 695 train loss: 0.04057766 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 696 train loss: 0.02619212 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 697 train loss: 0.03183145 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 698 train loss: 0.02456833 epoch time: 1.37s step time: 0.0109s\n",
      "epoch: 699 train loss: 0.03242403 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 700 train loss: 0.03279940 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.00580528\n",
      "=================================End Evaluation=================================\n",
      "epoch: 701 train loss: 0.03658760 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 702 train loss: 0.02302191 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 703 train loss: 0.04492426 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 704 train loss: 0.02338899 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 705 train loss: 0.02601144 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 706 train loss: 0.03032187 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 707 train loss: 0.03791646 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 708 train loss: 0.05689753 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 709 train loss: 0.02602798 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 710 train loss: 0.02461858 epoch time: 1.30s step time: 0.0104s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.005245948\n",
      "=================================End Evaluation=================================\n",
      "epoch: 711 train loss: 0.04052445 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 712 train loss: 0.01536433 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 713 train loss: 0.02093956 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 714 train loss: 0.02095050 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 715 train loss: 0.02138578 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 716 train loss: 0.02185764 epoch time: 1.33s step time: 0.0107s\n",
      "epoch: 717 train loss: 0.02239981 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 718 train loss: 0.02258344 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 719 train loss: 0.02326254 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 720 train loss: 0.02221634 epoch time: 1.30s step time: 0.0104s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.005415218\n",
      "=================================End Evaluation=================================\n",
      "epoch: 721 train loss: 0.01931702 epoch time: 1.37s step time: 0.0109s\n",
      "epoch: 722 train loss: 0.01926254 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 723 train loss: 0.03413431 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 724 train loss: 0.04181527 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 725 train loss: 0.02286670 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 726 train loss: 0.01613042 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 727 train loss: 0.02117444 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 728 train loss: 0.02628150 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 729 train loss: 0.02875881 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 730 train loss: 0.02229268 epoch time: 1.30s step time: 0.0104s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0045621116\n",
      "=================================End Evaluation=================================\n",
      "epoch: 731 train loss: 0.02687645 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 732 train loss: 0.02770655 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 733 train loss: 0.03056072 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 734 train loss: 0.01710372 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 735 train loss: 0.02232035 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 736 train loss: 0.02725480 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 737 train loss: 0.02516001 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 738 train loss: 0.03270333 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 739 train loss: 0.01453684 epoch time: 1.35s step time: 0.0108s\n",
      "epoch: 740 train loss: 0.01789373 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.004638773\n",
      "=================================End Evaluation=================================\n",
      "epoch: 741 train loss: 0.01787310 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 742 train loss: 0.02152637 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 743 train loss: 0.02884085 epoch time: 1.35s step time: 0.0108s\n",
      "epoch: 744 train loss: 0.02025483 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 745 train loss: 0.01973063 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 746 train loss: 0.02363576 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 747 train loss: 0.02350449 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 748 train loss: 0.02571641 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 749 train loss: 0.01954176 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 750 train loss: 0.02365989 epoch time: 1.30s step time: 0.0104s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0045262324\n",
      "=================================End Evaluation=================================\n",
      "epoch: 751 train loss: 0.02435545 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 752 train loss: 0.02515050 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 753 train loss: 0.02025899 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 754 train loss: 0.02445256 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 755 train loss: 0.03902057 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 756 train loss: 0.02172002 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 757 train loss: 0.02099918 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 758 train loss: 0.02200205 epoch time: 1.34s step time: 0.0108s\n",
      "epoch: 759 train loss: 0.02271363 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 760 train loss: 0.01253468 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0043898798\n",
      "=================================End Evaluation=================================\n",
      "epoch: 761 train loss: 0.01885824 epoch time: 1.35s step time: 0.0108s\n",
      "epoch: 762 train loss: 0.02465902 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 763 train loss: 0.01613273 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 764 train loss: 0.02111884 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 765 train loss: 0.02254438 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 766 train loss: 0.02743090 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 767 train loss: 0.02700382 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 768 train loss: 0.02472379 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 769 train loss: 0.01547623 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 770 train loss: 0.02132436 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.00456425\n",
      "=================================End Evaluation=================================\n",
      "epoch: 771 train loss: 0.03940897 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 772 train loss: 0.01317947 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 773 train loss: 0.02148420 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 774 train loss: 0.01576684 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 775 train loss: 0.02288622 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 776 train loss: 0.02153194 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 777 train loss: 0.02214362 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 778 train loss: 0.01762821 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 779 train loss: 0.01811804 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 780 train loss: 0.02326084 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0043316884\n",
      "=================================End Evaluation=================================\n",
      "epoch: 781 train loss: 0.01651670 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 782 train loss: 0.02329632 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 783 train loss: 0.02434926 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 784 train loss: 0.03081785 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 785 train loss: 0.01383317 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 786 train loss: 0.01974599 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 787 train loss: 0.01376799 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 788 train loss: 0.02282987 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 789 train loss: 0.01575530 epoch time: 1.38s step time: 0.0110s\n",
      "epoch: 790 train loss: 0.01652073 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.004085775\n",
      "=================================End Evaluation=================================\n",
      "epoch: 791 train loss: 0.02142633 epoch time: 1.35s step time: 0.0108s\n",
      "epoch: 792 train loss: 0.02192906 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 793 train loss: 0.01733931 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 794 train loss: 0.01791907 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 795 train loss: 0.01989889 epoch time: 1.34s step time: 0.0107s\n",
      "epoch: 796 train loss: 0.01567704 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 797 train loss: 0.02667042 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 798 train loss: 0.01906799 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 799 train loss: 0.02569301 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 800 train loss: 0.01938311 epoch time: 1.30s step time: 0.0104s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.004322123\n",
      "=================================End Evaluation=================================\n",
      "epoch: 801 train loss: 0.01627247 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 802 train loss: 0.02268281 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 803 train loss: 0.01434798 epoch time: 1.34s step time: 0.0108s\n",
      "epoch: 804 train loss: 0.01395404 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 805 train loss: 0.01596952 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 806 train loss: 0.01976899 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 807 train loss: 0.01723721 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 808 train loss: 0.01199169 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 809 train loss: 0.01519946 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 810 train loss: 0.03190085 epoch time: 1.31s step time: 0.0104s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.004515207\n",
      "=================================End Evaluation=================================\n",
      "epoch: 811 train loss: 0.01512913 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 812 train loss: 0.02039468 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 813 train loss: 0.01515356 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 814 train loss: 0.01351424 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 815 train loss: 0.01551749 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 816 train loss: 0.02375067 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 817 train loss: 0.01389846 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 818 train loss: 0.01083077 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 819 train loss: 0.01515184 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 820 train loss: 0.02820728 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0040564095\n",
      "=================================End Evaluation=================================\n",
      "epoch: 821 train loss: 0.01925767 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 822 train loss: 0.01803897 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 823 train loss: 0.01772045 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 824 train loss: 0.02369642 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 825 train loss: 0.02048478 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 826 train loss: 0.02529195 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 827 train loss: 0.02691754 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 828 train loss: 0.01449710 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 829 train loss: 0.01274944 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 830 train loss: 0.02043920 epoch time: 1.30s step time: 0.0104s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.004363282\n",
      "=================================End Evaluation=================================\n",
      "epoch: 831 train loss: 0.01453552 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 832 train loss: 0.01768313 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 833 train loss: 0.02419675 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 834 train loss: 0.01979177 epoch time: 1.35s step time: 0.0108s\n",
      "epoch: 835 train loss: 0.02958583 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 836 train loss: 0.02220444 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 837 train loss: 0.01794865 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 838 train loss: 0.02847636 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 839 train loss: 0.03035870 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 840 train loss: 0.01180221 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0039927424\n",
      "=================================End Evaluation=================================\n",
      "epoch: 841 train loss: 0.02215115 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 842 train loss: 0.01470441 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 843 train loss: 0.01601128 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 844 train loss: 0.02404735 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 845 train loss: 0.01387970 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 846 train loss: 0.01349061 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 847 train loss: 0.01400624 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 848 train loss: 0.01489286 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 849 train loss: 0.02064969 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 850 train loss: 0.01044001 epoch time: 1.31s step time: 0.0104s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0039390624\n",
      "=================================End Evaluation=================================\n",
      "epoch: 851 train loss: 0.01218290 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 852 train loss: 0.02489313 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 853 train loss: 0.02148119 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 854 train loss: 0.01311556 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 855 train loss: 0.02354142 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 856 train loss: 0.01005401 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 857 train loss: 0.01105099 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 858 train loss: 0.01202876 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 859 train loss: 0.01110269 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 860 train loss: 0.01789127 epoch time: 1.32s step time: 0.0106s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.004049409\n",
      "=================================End Evaluation=================================\n",
      "epoch: 861 train loss: 0.02185030 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 862 train loss: 0.01357005 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 863 train loss: 0.01847081 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 864 train loss: 0.02111883 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 865 train loss: 0.01842755 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 866 train loss: 0.01474158 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 867 train loss: 0.01391635 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 868 train loss: 0.01363373 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 869 train loss: 0.01160378 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 870 train loss: 0.01201012 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.003985667\n",
      "=================================End Evaluation=================================\n",
      "epoch: 871 train loss: 0.02111410 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 872 train loss: 0.02226205 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 873 train loss: 0.01891826 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 874 train loss: 0.01580139 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 875 train loss: 0.01711972 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 876 train loss: 0.02443366 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 877 train loss: 0.01380556 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 878 train loss: 0.02435981 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 879 train loss: 0.01647396 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 880 train loss: 0.01372158 epoch time: 1.36s step time: 0.0109s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0039824313\n",
      "=================================End Evaluation=================================\n",
      "epoch: 881 train loss: 0.01154489 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 882 train loss: 0.01466662 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 883 train loss: 0.01446295 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 884 train loss: 0.01791533 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 885 train loss: 0.02035595 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 886 train loss: 0.02175432 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 887 train loss: 0.00845375 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 888 train loss: 0.01341539 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 889 train loss: 0.02415346 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 890 train loss: 0.01398410 epoch time: 1.34s step time: 0.0107s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0038198326\n",
      "=================================End Evaluation=================================\n",
      "epoch: 891 train loss: 0.00976990 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 892 train loss: 0.01131612 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 893 train loss: 0.01559924 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 894 train loss: 0.01882637 epoch time: 1.33s step time: 0.0107s\n",
      "epoch: 895 train loss: 0.01219716 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 896 train loss: 0.00877847 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 897 train loss: 0.01905932 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 898 train loss: 0.00917287 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 899 train loss: 0.01530053 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 900 train loss: 0.01230714 epoch time: 1.30s step time: 0.0104s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0037839902\n",
      "=================================End Evaluation=================================\n",
      "epoch: 901 train loss: 0.01331830 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 902 train loss: 0.00862300 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 903 train loss: 0.01901059 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 904 train loss: 0.01739518 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 905 train loss: 0.01070936 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 906 train loss: 0.01557267 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 907 train loss: 0.01046804 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 908 train loss: 0.01218029 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 909 train loss: 0.02316550 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 910 train loss: 0.01310678 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.003771763\n",
      "=================================End Evaluation=================================\n",
      "epoch: 911 train loss: 0.01236396 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 912 train loss: 0.01442049 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 913 train loss: 0.00941830 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 914 train loss: 0.01659479 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 915 train loss: 0.01029676 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 916 train loss: 0.00990394 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 917 train loss: 0.01239099 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 918 train loss: 0.01375866 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 919 train loss: 0.01923414 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 920 train loss: 0.01724004 epoch time: 1.32s step time: 0.0106s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0037370785\n",
      "=================================End Evaluation=================================\n",
      "epoch: 921 train loss: 0.01985597 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 922 train loss: 0.01444442 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 923 train loss: 0.01131195 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 924 train loss: 0.01938980 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 925 train loss: 0.01286144 epoch time: 1.36s step time: 0.0109s\n",
      "epoch: 926 train loss: 0.00902410 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 927 train loss: 0.01365145 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 928 train loss: 0.01075735 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 929 train loss: 0.01948422 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 930 train loss: 0.01766817 epoch time: 1.30s step time: 0.0104s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0037702275\n",
      "=================================End Evaluation=================================\n",
      "epoch: 931 train loss: 0.01200326 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 932 train loss: 0.00727339 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 933 train loss: 0.00841095 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 934 train loss: 0.01656225 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 935 train loss: 0.01287463 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 936 train loss: 0.01852619 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 937 train loss: 0.02071554 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 938 train loss: 0.01914443 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 939 train loss: 0.01336513 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 940 train loss: 0.00867372 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0037609495\n",
      "=================================End Evaluation=================================\n",
      "epoch: 941 train loss: 0.01954800 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 942 train loss: 0.01159992 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 943 train loss: 0.01685077 epoch time: 1.32s step time: 0.0105s\n",
      "epoch: 944 train loss: 0.00734864 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 945 train loss: 0.01639749 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 946 train loss: 0.01088865 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 947 train loss: 0.01389877 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 948 train loss: 0.00786886 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 949 train loss: 0.00956977 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 950 train loss: 0.01167121 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0037516481\n",
      "=================================End Evaluation=================================\n",
      "epoch: 951 train loss: 0.02372139 epoch time: 1.32s step time: 0.0106s\n",
      "epoch: 952 train loss: 0.01429889 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 953 train loss: 0.00836949 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 954 train loss: 0.01233537 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 955 train loss: 0.01297407 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 956 train loss: 0.02023454 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 957 train loss: 0.01079210 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 958 train loss: 0.00911969 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 959 train loss: 0.01460938 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 960 train loss: 0.01015542 epoch time: 1.31s step time: 0.0105s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0037204975\n",
      "=================================End Evaluation=================================\n",
      "epoch: 961 train loss: 0.02539158 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 962 train loss: 0.01368681 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 963 train loss: 0.00922953 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 964 train loss: 0.01164698 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 965 train loss: 0.01061562 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 966 train loss: 0.00808317 epoch time: 1.33s step time: 0.0106s\n",
      "epoch: 967 train loss: 0.01523831 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 968 train loss: 0.01487047 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 969 train loss: 0.01744178 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 970 train loss: 0.00873110 epoch time: 1.30s step time: 0.0104s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0037179166\n",
      "=================================End Evaluation=================================\n",
      "epoch: 971 train loss: 0.01294354 epoch time: 1.35s step time: 0.0108s\n",
      "epoch: 972 train loss: 0.01419585 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 973 train loss: 0.01316358 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 974 train loss: 0.01668494 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 975 train loss: 0.01826360 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 976 train loss: 0.00967836 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 977 train loss: 0.01257684 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 978 train loss: 0.01045731 epoch time: 1.28s step time: 0.0103s\n",
      "epoch: 979 train loss: 0.00958386 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 980 train loss: 0.00880955 epoch time: 1.29s step time: 0.0103s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.00372047\n",
      "=================================End Evaluation=================================\n",
      "epoch: 981 train loss: 0.00957520 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 982 train loss: 0.01066005 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 983 train loss: 0.01515190 epoch time: 1.29s step time: 0.0104s\n",
      "epoch: 984 train loss: 0.01254391 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 985 train loss: 0.01107685 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 986 train loss: 0.01177527 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 987 train loss: 0.01466691 epoch time: 1.31s step time: 0.0104s\n",
      "epoch: 988 train loss: 0.01102164 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 989 train loss: 0.01020285 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 990 train loss: 0.01447960 epoch time: 1.29s step time: 0.0103s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0037082783\n",
      "=================================End Evaluation=================================\n",
      "epoch: 991 train loss: 0.01156847 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 992 train loss: 0.00886589 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 993 train loss: 0.02118509 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 994 train loss: 0.00915443 epoch time: 1.29s step time: 0.0103s\n",
      "epoch: 995 train loss: 0.00686897 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 996 train loss: 0.01654900 epoch time: 1.31s step time: 0.0105s\n",
      "epoch: 997 train loss: 0.02281374 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 998 train loss: 0.00882281 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 999 train loss: 0.00854049 epoch time: 1.30s step time: 0.0104s\n",
      "epoch: 1000 train loss: 0.01368600 epoch time: 1.29s step time: 0.0103s\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.0037078187\n",
      "=================================End Evaluation=================================\n"
     ]
    }
   ],
   "source": [
    "problem = UnsteadyFlowWithLoss(model, loss_fn=RelativeRMSELoss(), data_format=\"NHWTC\")\n",
    "\n",
    "summary_dir = os.path.join(config[\"summary\"][\"summary_dir\"], model_name)\n",
    "if not os.path.exists(summary_dir):\n",
    "    os.makedirs(summary_dir)\n",
    "print(summary_dir)\n",
    "\n",
    "def forward_fn(data, label):\n",
    "    loss = problem.get_loss(data, label)\n",
    "    if use_ascend:\n",
    "        loss = loss_scaler.scale(loss)\n",
    "    return loss\n",
    "\n",
    "grad_fn = ops.value_and_grad(forward_fn, None, optimizer.parameters, has_aux=False)\n",
    "\n",
    "@jit\n",
    "def train_step(data, label):\n",
    "    loss, grads = grad_fn(data, label)\n",
    "    if use_ascend:\n",
    "        loss = loss_scaler.unscale(loss)\n",
    "        if all_finite(grads):\n",
    "            grads = loss_scaler.unscale(grads)\n",
    "    loss = ops.depend(loss, optimizer(grads))\n",
    "    return loss\n",
    "\n",
    "\n",
    "sink_process = data_sink(train_step, train_dataset, 1)\n",
    "ckpt_dir = os.path.join(summary_dir, \"ckpt\")\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)\n",
    "print(ckpt_dir)\n",
    "    \n",
    "print(optimizer_params[\"epochs\"])\n",
    "    \n",
    "for epoch in range(1, optimizer_params[\"epochs\"] + 1):\n",
    "    model.set_train()\n",
    "    local_time_beg = time.time()\n",
    "    for _ in range(steps_per_epoch):\n",
    "        cur_loss = sink_process()\n",
    "    print(\n",
    "        f\"epoch: {epoch} train loss: {cur_loss.asnumpy():.8f}\"\\\n",
    "        f\" epoch time: {time.time() - local_time_beg:.2f}s\"\\\n",
    "        f\" step time: {(time.time() - local_time_beg)/steps_per_epoch:.4f}s\")\n",
    "\n",
    "    if epoch % config['summary']['test_interval'] == 0:\n",
    "        model.set_train(False)\n",
    "        print(\"================================Start Evaluation================================\")\n",
    "        rms_error = problem.get_loss(test_input, test_label)/test_input.shape[0]\n",
    "        print(f\"mean rms_error: {rms_error}\")\n",
    "        print(\"=================================End Evaluation=================================\")\n",
    "        save_checkpoint(model, os.path.join(ckpt_dir, model_params[\"name\"] + '_epoch' + str(epoch)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
